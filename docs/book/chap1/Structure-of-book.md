这本书的结构遵循 **第一章 介绍** 的结构。第2章至第9章详细介绍了监督学习流程。我们描述了浅层和深层神经网络，并讨论了如何训练它们以及如何测量和提高它们的性能。第10章至第13章描述了深层神经网络的常见架构变体，包括卷积网络、残差连接和transformers。这些架构在监督学习、无监督学习和强化学习中都有应用。

第14至18章探讨了使用深度神经网络的无监督学习。我们分别为四种现代深度生成模型各专门设立了一章：生成对抗网络、变分自编码器、归一化流和扩散模型。第19章是对深度强化学习的简要介绍。这是一个很容易就能单独成书的主题，因此这里的处理必然是肤浅的。然而，这种处理旨在为不熟悉这一领域的读者提供一个良好的起点。

尽管这本书的标题如此，深度学习的某些方面仍然理解不足。第20章提出了一些基本问题。为什么深度网络这么容易训练？为什么它们泛化得这么好？为什么它们需要这么大？它们需要很深吗？在此过程中，我们探讨了损失函数的结构、双重下降、摸索和彩票票号等意外现象。这本书以第21章结束，讨论了深度学习的伦理问题。