如果不讨论人工智能的伦理影响，写这本书将是不负责任的。这项强大的技术至少会像电力、内燃机、晶体管或互联网一样改变世界。在医疗保健、设计、娱乐、交通、教育以及几乎所有商业领域，潜在的好处是巨大的。然而，科学家和工程师往往对他们工作的成果抱有不切实际的乐观态度，潜在的危害也同样巨大。以下段落重点介绍了五个令人关注的问题。

**偏见与公平性：** 如果我们训练一个系统根据历史数据来预测个人的薪水水平，那么这个系统将会复制历史上的偏见；例如，它可能会预测女性的薪酬应该低于男性。已经有几个这样的案例成为了国际新闻：一个用于超分辨率人脸图像的AI系统使得非白人看起来更白；一个生成图像的系统在被要求合成律师图片时只产生了男性的照片。算法决策在AI中的不小心应用有可能固化或加剧现有的偏见。有关进一步讨论，请参见Binns（2018）<sup style="color: green;">[1]</sup>。

**可解释性：** 深度学习系统会做出决策，但我们通常不知道深度学习系统是如何做出决策的，或基于哪些信息。它们可能非常庞大，而我们却无法通过考察了解它们是如何工作的。这就催生了可解释人工智能这一子领域。我们无法解释整个系统，但我们可以对为何做出特定决定做出可解释的描述。然而，我们仍然不知道是否有可能建立对用户甚至创造者完全透明的复杂决策系统。有关更多信息，请参见Grennan等人（2022年）<sup style="color: green;">[2]</sup>。

**武器化人工智能：** 所有重大技术都直接或间接地应用于战争。不幸的是，暴力冲突似乎是人类行为的不可避免的特征。人工智能可以说是有史以来最强大的技术，无疑将在军事领域得到广泛部署。事实上，这已经在发生（Heikkilä，2022）<sup style="color: green;">[3]</sup>。

**集中权力：** 世界上最强大的公司大力投资人工智能，并非出于对改善人类命运的仁慈兴趣。他们知道这些技术将使他们能够获得巨大的利润。像任何先进技术一样，深度学习可能会将权力集中在控制它的少数组织手中。自动化目前由人类完成的工作将改变经济环境，并不成比例地影响低薪、技能较少的工人的生计。乐观者认为，在工业革命期间也发生过类似的破坏，导致了更短的工作时间。事实是，我们根本不知道大规模采用人工智能将对社会产生什么影响（参见David，2015年）<sup style="color: green;">[4]</sup>。

**存在风险：** 对人类构成重大存在风险的主要是技术。气候变化是由工业化驱动的。核武器源自物理学的研究。由于交通、农业和建筑的创新，使得人口更多、更密集、更互联互通，因此大流行病更有可能发生并且传播速度更快。人工智能带来了新的存在风险。我们应该非常谨慎地构建比人类更有能力、更可扩展的系统。在最乐观的情况下，它将把巨大的权力交给所有者。在最悲观的情况下，我们将无法控制它，甚至无法理解它的动机（参见Tegmark，2018年）<sup style="color: green;">[5]</sup>。

这个列表远非详尽。人工智能还可能启用监视、虚假信息、侵犯隐私、欺诈以及操纵金融市场，而且训练人工智能系统所需的能源会导致气候变化。此外，这些担忧并非推测；已经有许多关于人工智能伦理可疑应用的例子（参见Dao，2021年，部分列表）<sup style="color: green;">[6]</sup>。另外，互联网的近期历史已经表明新技术会以意想不到的方式造成伤害。八十年代和九十年代初的在线社区几乎无法预测假新闻、垃圾邮件、在线骚扰、欺诈、网络欺凌、非自愿独身文化、政治操纵、人肉搜索、在线激进化和复仇色情内容的泛滥。

每个研究或研究（或撰写关于人工智能的书籍）的人都应该思考科学家对其技术使用的责任程度。我们应该考虑到资本主义主要是推动人工智能的发展，而法律进步和社会利益的部署可能会大大滞后。我们应该反思作为科学家和工程师，是否有可能控制这一领域的进步并减少潜在的危害。我们应该考虑我们准备为哪种组织工作。他们在减少人工智能潜在危害方面的承诺有多严肃？他们仅仅是在进行“道德洗白”以降低声誉风险，还是实际上实施了机制来阻止道德上可疑的项目？

所有读者都被鼓励进一步探究这些问题。在线课程（ https://ethics-of-ai.mooc.fi/ ）是一个有用的入门资源。如果你是一名教授，正在使用这本书授课，我们鼓励你向学生提出这些问题。如果你是一名学生，在你所上的课程中没有涉及这些问题，那么游说你的教授让他做到这一点。如果你在企业环境中部署或研究人工智能，我们鼓励你审查你雇主的价值观，并帮助改变它们（或者离开），如果它们不符合期望的话。

::: tip 注
[1] Binns, R. (2018). Algorithmic accountability and
public reason. Philosophy & Technology, 31(4), 543–556. 

[2] Grennan, L., Kremer, A., Singla, A., & Zipparo,
P. (2022). Why businesses need explainable AI—and how to deliver it. McKinsey, Septem-ber 29, 2022. https://www.mckinsey.com/capabilities/quantumblack/our-insights/why-businesses-need-explainable-ai-and-how-to-deliver-it/.

[3] Heikkilä, M. (2022). Why business is booming for
military AI startups. MIT Technology Review, July 7 2022. https://www.technologyreview.com/2022/07/07/1055526/why-business-is-booming-for-military-ai-startups/.

[4] David, H. (2015). Why are there still so many jobs?
The history and future of workplace automa-tion. Journal of Economic Perspectives, 29(3), 3–30. 

[5] Tegmark, M. (2018). Life 3.0: Being human in the
age of artificial intelligence. Vintage.

[6] Dao, D. (2021).Awful AI. Github. 
Retrieved January 17, 2023. https://github.com/daviddao/awful-ai. 
:::
